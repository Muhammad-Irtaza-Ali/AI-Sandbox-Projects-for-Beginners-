{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "446837b9-5f2a-4abe-8dea-b3fd45ee1510",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "dialogue = \"\"\"\n",
    "Character A: \"The galaxy is in turmoil. The rebels are fighting\n",
    "to overthrow the empire, and we need to find a way to communicate\n",
    "with the leaders. We can't let the forces of darkness take over our\n",
    "world.\"\n",
    "Character B: \"I agree. The resistance is our only hope. But how\n",
    "can we gain support from the people? We need a strategy to win their\n",
    "hearts and minds, to unite them against the empire.\"\n",
    "Character A: \"We must focus on the key battles and disrupt their communication lines.\n",
    "We also need to create a powerful message that inspires hope. If we\n",
    "can sway public opinion, we can win this war.\"\n",
    "\"\"\"\n",
    "\n",
    "tokens = word_tokenize(dialogue)\n",
    "\n",
    "lower_tokens=[]\n",
    "for t in tokens:\n",
    "    lower_tokens.append(t.lower())\n",
    "\n",
    "bow_simple = Counter(lower_tokens)\n",
    "\n",
    "print(bow_simple.most_common(5))\n",
    "   \n",
    "\n",
    "print(lower_tokens)\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "alpha_only=[]\n",
    "for t in lower_tokens:\n",
    "    if t.isalpha():\n",
    "        alpha_only.append(t)\n",
    "\n",
    "print(alpha_only)\n",
    "\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "\n",
    "\n",
    "no_stops=[]\n",
    "for t in alpha_only:\n",
    "    if t not in stopwords.words('english'):\n",
    "        no_stops.append(t)\n",
    "\n",
    "print(no_stops)\n",
    "\n",
    " \n",
    "wordnet_lemmatizer=WordNetLemmatizer()\n",
    "lemmatized_tokens=[]\n",
    "for t in no_stops:\n",
    "    lemmatized_token=wordnet_lemmatizer.lemmatize(t)\n",
    "    lemmatized_tokens.append(lemmatized_token)\n",
    "\n",
    "print(lemmatized_tokens)\n",
    "\n",
    "bow = Counter(lemmatized_tokens)\n",
    "\n",
    "print(bow.most_common(10))\n",
    "\n",
    "custom_stopwords=[\"character\",\"need\"] \n",
    "no_stops=[]\n",
    "for t in alpha_only:\n",
    "    if t not in stopwords.words('english') and t not in custom_stopwords:\n",
    "        no_stops.append(t)\n",
    "\n",
    "print(no_stops)\n",
    "\n",
    "\n",
    "bow=Counter(no_stops)\n",
    "print(bow.most_common(10))\n",
    "\n",
    "#so empire is topic word\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
